{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02720f45-8025-4cc2-80e3-af9580fd625c",
   "metadata": {},
   "source": [
    "# Report: Recipe Discovery - predicting popularity\n",
    "This report presents a comprehensive analysis of predicting high traffic recipes on a recipe discovery platform. The study involves data validation, preprocessing, exploratory analysis, and model development using Logistic Regression and Support Vector Machine (SVM) models. The models were evaluated based on performance metrics such as accuracy, precision, recall, F1 score, and ROC AUC score. The results indicate that both models are effective in predicting high traffic recipes, with Logistic Regression excelling in precision and SVM demonstrating higher recall. Cross-validation results further support the stability and reliability of the models. Feature importance analysis highlights key predictors, including Beverages, Breakfast, Vegetable, and Potato. The report concludes with recommendations for model selection, feature optimization, and business metrics monitoring to enhance user engagement and revenue generation. The findings provide actionable insights for optimizing recipe content and improving traffic predictions, ultimately supporting the platform's business objectives.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e8fc2a-d71e-4d8d-909e-82f5f4ad52c4",
   "metadata": {},
   "source": [
    "## Data Validation & Preprocessing\n",
    "Data preprocessing for model development included the following steps:  \n",
    "- **Recipe Column**: The recipe column is a unique identifier. This was confirmed by verifying that the recipe column has 947 unique values. To ensure that the unique identifier does not influence the model's predictions, the recipe column was dropped from the training data.\n",
    "```python\n",
    "# Verify that the 'recipe' column has 947 unique entries\n",
    "identifier = df['recipe'].nunique()\n",
    "print(f\"There's 947 rows in the dataset. The number of unique identifiers is {identifier}.\")\n",
    "```\n",
    "```\n",
    "There's 947 rows in the dataset. The number of unique identifiers is 947.\n",
    "```\n",
    "```python\n",
    "# Drop the 'recipe' column as it is a unique identifier and not included in the model\n",
    "df = df.drop('recipe', axis=1)\n",
    "```\n",
    "- **Category Column**: The category column represents the type of cuisine and has no inherent order, classifying it as nominal data. Therefore, the category column was one-hot encoded to binary format using the pandas get_dummies() function.\n",
    "```python\n",
    "# One-hot encode the 'category' column and remove the 'category_' prefix from column names\n",
    "df = pd.get_dummies(df, columns=['category'])\n",
    "df.columns = [col.replace('category_', '') for col in df.columns]\n",
    "```\n",
    "- **Servings Column**: The servings column has a natural order (1 < 2 < 4 < 6), making it ordinal data. To label encode the data, the servings column was stripped of trailing text and converted to integers.\n",
    "\n",
    "```python\n",
    "# Clean and convert the 'servings' column to integer, and capitalize the column name for plotting\n",
    "df['servings'] = df['servings'].str.replace(' as a snack', '').astype(int)\n",
    "df.rename(columns={'servings': 'Servings'}, inplace=True)\n",
    "```\n",
    "- **High Traffic Column**: The high_traffic column was converted to binary format where 1 represents 'High' and 0 represents 'Low'.\n",
    "```python\n",
    "# Convert 'high_traffic' column to binary form: 1 if 'High', else 0\n",
    "df['high_traffic'] = df['high_traffic'].apply(lambda x: 1 if x == 'High' else 0)\n",
    "```\n",
    "- **Handling High Variance and Missing Values**: Following steps were taken to handle high variance and missing values in calories, carbohydrate, sugar, and protein columns:\n",
    "    - **Calculate and Print Column Variances**: Variances were calculated to identify columns with high variance.\n",
    "    ```python\n",
    "    # Calculate and print column variances\n",
    "    variances = df.var()\n",
    "    print(\"\\nVariances:\")\n",
    "    print(variances)\n",
    "    ```\n",
    "    - **Impute Missing Values**: Missing values in the high variance columns were imputed using KNNImputer with 3 neighbors.\n",
    "    ```python\n",
    "    # Imputate missing values in highvar_cols\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    df[highvar_cols] = imputer.fit_transform(df[highvar_cols])\n",
    "    ```\n",
    "    - **Log Transform**: High variance columns were log-transformed to reduce the impact of variance.\n",
    "    ```python\n",
    "    # Log transform highvar_cols to reduce the impact of variance\n",
    "    def log_transform(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = np.log1p(df[column])\n",
    "    return df\n",
    "    df = log_transform(df, highvar_cols)\n",
    "    ```\n",
    "By imputing missing values and applying log transformation, the data quality was improved, allowing the inclusion of all datapoints in the model training process. This approach helps reduce bias and enhances model accuracy and training efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc368f0b-b478-4aa0-bbe6-510a666edab4",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "![Pie Chart](dscert_traffic.png)\n",
    "*Figure 1: The traffic distribution for all recipes on the portal.*  \n",
    "\n",
    "Figure 1 shows that a majority, 61%, of the observations are classified as \"High\" traffic, indicating that most recipes receive a significant amount of visits. The remaining 39% of the observations are categorized as \"Low\" traffic, representing recipes with lower traffic.  \n",
    "\n",
    "![Bar Chart](dscert_servings.png)\n",
    "*Figure 2: The number of recipes categorized by the number of servings they provide. The serving sizes are divided into four categories: 1, 2, 4, and 6 servings.*  \n",
    "\n",
    "Figure 2 shows that recipes designed for 4 servings are the most common, with a total of 391 recipes. This is followed by recipes for 6 servings (198 recipes), 2 servings (183 recipes), and 1 serving (175 recipes). This distribution suggests that recipes catering to medium-sized groups (4 servings) are twice as common on the portal compared to other serving sizes.  \n",
    "\n",
    "![Bar Chart](dscert_comparison.png)\n",
    "*Figure 3: The distribution of recipe postings categorized by serving sizes and their corresponding traffic levels (High vs. Low).*  \n",
    "\n",
    "Figure 3 shows that recipes with higher serving sizes tend to have proportionally more \"High\" traffic postings. Specifically, the 4- and 6-servings categories show a significantly higher ratio of \"High\" to \"Low\" traffic recipes of 1.54 and 1.86 respectively. This is in comparison to 1- and 2-servings categories showing a ratio of 1.43 and 1.35 respectively. This trend suggests that recipes designed to serve more people are more popular and attract higher traffic on the platform.\n",
    "\n",
    "### Findings\n",
    "- **Serving Size Popularity**: Recipes designed for 4 servings are the most common, indicating a preference for recepies of medium-sized group meals.\n",
    "- **Traffic Distribution**: A significant majority of recipes receive high traffic, suggesting that the portal is effective in attracting visitors to its content.\n",
    "- **Serving Size and Traffic**: Recipes with larger serving sizes (4 and 6 servings) tend to attract more traffic, highlighting the popularity of recipes that cater to more people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f097e7d-c51f-49bf-8277-fc87e44eaa93",
   "metadata": {},
   "source": [
    "## Model Development\n",
    "**Problem Statement**: The task at hand is a binary classification problem where the goal is to predict whether a recipe will generate high traffic based on various features. The dataset consists of 947 rows with the following columns:\n",
    "\n",
    "- Four columns of log-transformed values representing calories, carbohydrate, protein, and sugar.\n",
    "- One column of label encoded categorical data representing serving size with 4 potential values (1, 2, 4, 6).\n",
    "- One-hot encoded categorical data with 11 potential values.\n",
    "- A binary target variable indicating high traffic (1 for High, 0 for Low).\n",
    "\n",
    "**Model Selection**:  \n",
    "```python\n",
    "# Select models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=12), \n",
    "    \"Support Vector Machine\": SVC(kernel='rbf', random_state=12, probability=True)\n",
    "}\n",
    "```  \n",
    "\n",
    "Given the nature of the dataset and the problem, Logistic Regression and Support Vector Machine (SVM) models were chosen for the following reasons:  \n",
    "\n",
    "**Logistic Regression**:\n",
    "- **Simplicity and Interpretability**: Logistic Regression serves as a baseline model due to its simplicity and interpretability. It is a straightforward model that provides easily interpretable coefficients, making it simple to understand the relationship between features and the target variable.\n",
    "- **Performance on Small Datasets**: Logistic Regression performs well on small datasets, such as the one at hand with 947 rows.\n",
    "- **Binary Classification**: It is well-suited for binary classification problems, which aligns with our target variable.\n",
    "\n",
    "**Support Vector Machine (SVM)**:\n",
    "- **Handling Non-linear Relationships**: SVM with an RBF kernel can handle non-linear relationships between features, making it a powerful model for complex datasets.\n",
    "- **Robustness and Accuracy**: SVM is known for its robustness and ability to provide high accuracy and generalization performance.\n",
    "- **Probability Estimates**: The probability=True parameter allows SVM to provide probability estimates.\n",
    "\n",
    "### Steps for fitting the models \n",
    "\n",
    "**Splitting the Data**:\n",
    "Split the data into features and the target variable to prepare for model training.\n",
    "```python\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop('high_traffic', axis=1)\n",
    "y = df['high_traffic']\n",
    "```\n",
    "\n",
    "**Train-Test Split**:\n",
    "Split the data into training and testing sets to evaluate the models' performance on unseen data. This step is crucial for assessing the generalization ability of the models.The test_size parameter is set to 0.2 to allocate sufficient amount of data for both training and testing to ensure a balanced evaluation of model performance.\n",
    "```python\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "```\n",
    "\n",
    "**Fitting the Models**:\n",
    "Fit the models on the training data to prepare them for making predictions.\n",
    "```python\n",
    "# Fit the models on the training data\n",
    "models[\"Logistic Regression\"].fit(X_train, y_train)\n",
    "print(\"\\nLogistic Regression trained successfully.\")\n",
    "models[\"Support Vector Machine\"].fit(X_train, y_train)\n",
    "print(\"\\nSupport Vector Machine trained successfully.\")\n",
    "```\n",
    "By following these steps, the Logistic Regression and Support Vector Machine models are trained on the recipe site traffic dataset, ready for evaluation and prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d8ae05-b0a2-463a-9e3a-8c3a34bf20d6",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "### Performance Metrics\n",
    "To evaluate the performance of the Logistic Regression and Support Vector Machine (SVM) models, several metrics were used: Accuracy, Precision, Recall, F1 Score, and ROC AUC Score. These metrics provide a comprehensive view of the models' effectiveness in predicting high traffic for recipes.\n",
    "\n",
    "```python\n",
    "# Function to print evaluation metrics for a model\n",
    "def print_metrics(y_true, y_pred, y_proba=None):\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred),\n",
    "        \"Recall\": recall_score(y_true, y_pred),\n",
    "        \"F1 Score\": f1_score(y_true, y_pred),\n",
    "        \"ROC AUC Score\": roc_auc_score(y_true, y_proba) if y_proba is not None else None\n",
    "    }\n",
    "    for metric, score in metrics.items():\n",
    "        if score is not None:\n",
    "            print(f\"{metric}: {score:.3f}\")\n",
    "\n",
    "# Calculate and print metrics for each model using the models variable\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name} Metrics:\")\n",
    "    predictions = model.predict(X_test)\n",
    "    probabilities = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    print_metrics(y_test, predictions, probabilities)\n",
    "```\n",
    "![Bar Chart](dscert_performance.png)\n",
    "*Figure 4: Comparison of accuracy, precision, recall, F1 Score, and ROC AUC Score for both models.*\n",
    "\n",
    "Figure 4 provides a visual comparison of model performance across different metrics. Both models achieve the 80 % goal for accuracy and have similar ROC AUC scores. Logistic Regression slightly outperforms SVM in terms of precision, indicating it is better at avoiding incorrect high traffic predictions. However, SVM has a higher recall and F1 score, suggesting it is better at identifying true high traffic recipes.\n",
    "\n",
    "### ROC Curves  \n",
    "ROC curves plot the true positive rate against the false positive rate for different threshold values. The area under the curve (AUC) provides a single metric to compare the models' performance.  \n",
    "![Line Chart](dscert_roc.png)\n",
    "*Figure 5: ROC Curves for Logistic Regression and Support Vector Machine models.*  \n",
    "\n",
    "Figure 5 shows that both models have similar ROC AUC scores, indicating comparable performance.\n",
    "\n",
    "### Confusion Matrices\n",
    "Confusion matrices display the number of true positives, true negatives, false positives, and false negatives.  \n",
    "\n",
    "![Confusion Matrix](dscert_matricies.png)\n",
    "*Figure 6: Confusion matrices for Logistic Regression and Support Vector Machine models.*  \n",
    "\n",
    "Figure 6 shows that both Logistic Regression and Random Forest models   into their performance in classifying high traffic recipes. provides insights into the performance of both Logistic Regression and Support Vector Machine (SVM) for classifying high traffic recipes. Logistic Regression correctly identified 53 instances of low traffic, while SVM correctly identified 44 instances. indicates that Logistic Regression is better at correctly identifying recipes that do not generate high traffic. Logistic Regression had 20 false positives, whereas SVM had only 8, suggesting that SVM is more conservative in predicting high traffic, resulting in fewer incorrect high traffic predictions. This aligns with SVM's higher precision, as it avoids labeling low traffic recipes as high traffic.Logistic Regression had 18 false negatives compared to SVM's 27. This indicates that Logistic Regression is better at identifying true high traffic recipes, as it misses fewer high traffic instances. However, SVM's higher number of false negatives suggests it is more cautious, potentially sacrificing recall for precision. Logistic Regression correctly identified 99 high traffic instances, while SVM correctly identified 111. This shows that SVM is more effective at identifying true high traffic recipes, which is reflected in its higher recall. SVM's ability to correctly identify more high traffic instances makes it a strong candidate for applications where identifying high traffic recipes is crucial.\n",
    "\n",
    "In summary, both models have their strengths and weaknesses. Logistic Regression excels in precision, making it suitable for applications where false positives are costly. SVM, with its higher recall, is ideal for scenarios where capturing all high traffic instances is critical. The decision on which model to use should be based on the specific needs and priorities of the task at hand.\n",
    "\n",
    "### Feature Scaling & Hyperparameter Tuning\n",
    "\n",
    "This section focuses on scaling the features, defining models, setting parameter grids, and performing hyperparameter tuning using RandomizedSearchCV to find the best parameters for Logistic Regression and Support Vector Machine (SVM) models.\n",
    "\n",
    "**Scale the Features**: The features are scaled using MaxAbsScaler to standardize the data.\n",
    "```python\n",
    "# Scale the features\n",
    "scaler = MaxAbsScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "**Set Parameter Grids for RandomizedSearchCV**: Parameter grids are defined for both Logistic Regression and SVM models to explore a range of hyperparameters.\n",
    "```python\n",
    "# Define parameter grids for RandomizedSearchCV\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "```\n",
    "**Perform RandomizedSearchCV**: RandomizedSearchCV is used to find the best parameters for selected models and the models dictionary is updated with the best estimators found through RandomizedSearchCV.\n",
    "```python\n",
    "# Perform RandomizedSearchCV for Logistic Regression\n",
    "random_search_lr = RandomizedSearchCV(models[\"Logistic Regression\"], param_grid_lr, n_iter=20, cv=StratifiedKFold(n_splits=4), random_state=12)\n",
    "random_search_lr.fit(X_train, y_train)\n",
    "models[\"Logistic Regression\"] = random_search_lr.best_estimator_\n",
    "\n",
    "# Perform RandomizedSearchCV for Support Vector Machine\n",
    "random_search_svc = RandomizedSearchCV(models[\"Support Vector Machine\"], param_grid_svc, n_iter=20, cv=StratifiedKFold(n_splits=4), random_state=12)\n",
    "random_search_svc.fit(X_train, y_train)\n",
    "models[\"Support Vector Machine\"] = random_search_svc.best_estimator_\n",
    "```\n",
    "By scaling the features and performing hyperparameter tuning, the models are optimized for better performance. The best parameters for each model are identified and used to update the models dictionary, ensuring that the Logistic Regression and SVM models are configured with the most effective hyperparameters for the given dataset.  \n",
    "\n",
    "### Cross-Validation\n",
    "\n",
    "Both models were evaluated using cross-validation to obtain mean scores and standard deviations for multiple metrics. Cross-validation helps in assessing the stability and reliability of the models by providing performance metrics averaged over multiple folds.  \n",
    "\n",
    "**Stratified K-Fold Cross-Validation**: Stratified K-Fold Cross-Validation ensures that the model performance metrics are reflective of true capabilities. This technique helps maintain the distribution of the target variable across training and validation sets, leading to more reliable and unbiased performance estimates.\n",
    "```python\n",
    "# Function to evaluate models and calculate feature importances\n",
    "def evaluate_model(model):\n",
    "    scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=StratifiedKFold(n_splits=4), scoring=scoring)\n",
    "    mean_scores = {metric: cv_results[f'test_{metric}'].mean() for metric in scoring}\n",
    "    std_scores = {metric: cv_results[f'test_{metric}'].std() for metric in scoring}\n",
    "    feature_importances = abs(model.coef_[0]) if isinstance(model, LogisticRegression) else permutation_importance(model, X_test, y_test, n_repeats=20, random_state=12).importances_mean\n",
    "    return mean_scores, std_scores, feature_importances\n",
    "\n",
    "# Evaluate models and store metrics\n",
    "cv_metrics = {\"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"ROC AUC\"]}\n",
    "feature_importances_dict = {}\n",
    "for model_name, model in models.items():\n",
    "    mean_scores, std_scores, feature_importances = evaluate_model(model)\n",
    "    cv_metrics.update({f\"{model_name} Mean\": list(mean_scores.values()), f\"{model_name} Std Dev\": list(std_scores.values())})\n",
    "    feature_importances_dict[model_name] = feature_importances\n",
    "\n",
    "# Print the mean scores and standard deviations for all metrics after cross-validation\n",
    "for model_name in models.keys():\n",
    "    print(f\"\\n{model_name} Cross-Validation Metrics:\")\n",
    "    for metric in cv_metrics[\"Metric\"]:\n",
    "        mean_score = cv_metrics[f\"{model_name} Mean\"][cv_metrics['Metric'].index(metric)]\n",
    "        std_dev = cv_metrics[f\"{model_name} Std Dev\"][cv_metrics['Metric'].index(metric)]\n",
    "        print(f\"{metric} - Mean: {mean_score:.3f}, Std Dev: {std_dev:.3f}\")\n",
    "```\n",
    "![Error Chart](dscert_cross.png)\n",
    "*Figure 7: Cross-validation performance metrics for Logistic Regression and Support Vector Machine. The evaluated metrics include Accuracy, Precision, Recall, F1 Score, and ROC AUC, with error bars representing the standard deviations.*   \n",
    "\n",
    "Figure 7 illustrates that both models exhibit consistent performance across multiple metrics, with low standard deviations indicating stability. Logistic Regression slightly outperforms SVM in terms of ROC AUC, while SVM shows a marginally higher precision. The results suggest that both models are effective in predicting high traffic recipes, with each model having its strengths in different metrics.\n",
    "\n",
    "When comparing the metrics for model selection, we observe a shift in the performance characteristics of Logistic Regression and Support Vector Machine (SVM) before and after cross-validation.\n",
    "\n",
    "Initially, Logistic Regression shows better precision (0.846) and lower recall (0.832), indicating that it is more effective at avoiding false positives but less effective at capturing all true positives. This makes Logistic Regression suitable for scenarios where minimizing false positives is crucial, such as when incorrect high traffic predictions could lead to wasted resources or user dissatisfaction.\n",
    "\n",
    "However, after cross-validation, the precision of Logistic Regression drops to a mean of 0.785, and recall decreases slightly to a mean of 0.817. This shift suggests that while Logistic Regression still maintains a balance between precision and recall, its ability to avoid false positives is slightly reduced, and its recall is more consistent across different data splits.\n",
    "\n",
    "On the other hand, SVM initially demonstrates lower precision (0.804) but significantly higher recall (0.933), making it more effective at identifying true high traffic recipes. This is ideal for applications where capturing all high traffic instances is critical, even at the cost of more false positives.\n",
    "\n",
    "After cross-validation, SVM's precision improves slightly to a mean of 0.793, while recall drops to a mean of 0.804. This indicates that SVM's initial high recall might have been overestimated, and its performance is more balanced when evaluated across multiple data splits. The decrease in recall suggests that SVM is less aggressive in identifying true positives than initially thought, but it still maintains a reasonable balance between precision and recall.\n",
    "\n",
    "In summary, the initial metrics suggest that Logistic Regression is better for minimizing false positives, while SVM is better for maximizing true positive identification. However, cross-validation results indicate that both models have more balanced performance, with Logistic Regression maintaining a slight edge in precision and SVM showing consistent recall. The choice between the two models should consider the specific business objectives and the relative importance of precision versus recall.\n",
    "\n",
    "### Feature Importance\n",
    "The feature importance analysis provides insights into which features contribute most to the models predictions. Both models identify Beverages as the most important feature, indicating its strong influence on predicting high traffic recipes.  \n",
    "```python\n",
    "# Normalize and average feature importances\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Logistic Regression': feature_importances_dict['Logistic Regression'], \n",
    "                              'Support Vector Machine': feature_importances_dict['Support Vector Machine']})\n",
    "importance_df[['Logistic Regression', 'Support Vector Machine']] = MaxAbsScaler().fit_transform(importance_df[['Logistic Regression', 'Support Vector Machine']])\n",
    "importance_df['Average Importance'] = importance_df[['Logistic Regression', 'Support Vector Machine']].mean(axis=1)\n",
    "```  \n",
    "\n",
    "![Bar Chart](dscert_fiLR.png)\n",
    "*Figure 8: Feature Importances for Logistic Regression model*  \n",
    "\n",
    "**Logistic Regression**: Figure 8 shows that Beverages, Vegetable, and Potato are the top three features, indicating they have the most significant influence on predicting high traffic recipes.  \n",
    "\n",
    "![Bar Chart](dscert_fiSVM.png)  \n",
    "*Figure 9: Feature Importances for Support Vector Machine model.*  \n",
    "\n",
    "**Support Vector Machine**: Figure 9 shows that Beverages and Breakfast are the top two features, indicating they have the most significant influence on predicting high traffic recipes. In the SVM model, most features have a zero importance score. This means that these features do not contribute to the decision boundary created by the SVM. The SVM model relies heavily on a few key features (Beverages, Breakfast, and Chicken breast) to make predictions, ignoring the rest. This could be due to the nature of the SVM algorithm, which focuses on finding the optimal hyperplane that separates the classes, often relying on a subset of the most informative features.  \n",
    "\n",
    "Logistic Regression considers a broader range of features, with Vegetable, Potato, and Pork also having significant importance scores. Logistic Regression provides a more comprehensive view of feature importance, considering multiple features. SVM, on the other hand, focuses primarily on Beverages and Breakfast, with most other features having zero importance scores. SVM's reliance on fewer features suggests it may be more efficient but potentially less robust in capturing the full complexity of the data. \n",
    "\n",
    "Interestingly, the feature importance scores reveal that Servings has only a minimal effect on predicting high traffic, despite exploratory data analysis suggesting otherwise. This discrepancy highlights the importance of using multiple methods to understand feature relevance. While exploratory analysis indicated that recipes with larger serving sizes tend to attract more traffic, the models suggest that other features, such as Beverages and Breakfast, play a more critical role in driving high traffic.\n",
    "\n",
    "**Ensemble Method for Actionable Insights**:  \n",
    "To provide actionable insights for stakeholders, an ensemble method is applied. This method normalizes the feature importance scores from both models and averages them out to create a combined importance score for guiding business decisions. By combining the insights from both models we can focus on the most influential features (Beverages, Breakfast, Vegetable, and Potato) to optimize recipe content and improve traffic predictions. This ensemble approach ensures a balanced and comprehensive understanding of feature importance, leveraging the strengths of both Logistic Regression and SVM models.  \n",
    "\n",
    "![Bar Chart](dscert_fiEA.png)\n",
    "*Figure 10: Feature Importances provided by the ensamble method.*\n",
    "\n",
    "Figure 10 shows clearly 3 distinct categories of Features. **High Impact Features**: Beverages remains the most important feature, followed by Breakfast, Vegetable, and Potato. **Medium Impact Features**: Pork, Chicken breast, and Chicken also contribute significantly. **Low Impact Features**: Calories, Meat, One dish meal, Dessert, Protein, Carbohydrate, Sugar, Servings, and Lunch/snacks have lower importance scores.\n",
    "\n",
    "\n",
    "### Conclusion  \n",
    "The model evaluation process involved assessing performance metrics and analyzing feature importance for both Logistic Regression and Support Vector Machine (SVM) models.  \n",
    "\n",
    "- **Overall Performance**: Both models achieved the 80% accuracy goal and had similar ROC AUC scores. Logistic Regression slightly outperformed SVM in precision, making it better at avoiding incorrect high traffic predictions. SVM, however, had higher recall and F1 scores, indicating it is better at identifying true high traffic recipes.\n",
    "- **Model Choice**: The choice between Logistic Regression and SVM depends on the specific priorities of the application. Logistic Regression is preferable if minimizing false positives is crucial, while SVM is better suited for scenarios where capturing all high traffic instances is critical.  \n",
    "- **Feature Importance**: Both models identified Beverages as the most important feature for predicting high traffic recipes. Logistic Regression also highlighted Vegetable and Potato, while SVM emphasized Breakfast and Chicken breast.  \n",
    "\n",
    "In summary, both models are effective for this classification task, with each having its strengths in different metrics. Logistic Regression excels in precision, making it suitable for applications where false positives are costly. SVM, with its higher recall, is ideal for scenarios where identifying all high traffic recipes is crucial. The final decision on which model to use should consider the specific business objectives and the relative importance of precision versus recall. The evaluation results provide a comprehensive understanding of the models' capabilities and highlight the importance of key features in driving predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d0817-db10-48c7-a0e9-6f2397f45ff4",
   "metadata": {},
   "source": [
    "## Business Metrics\n",
    "To effectively compare model performance to business objectives, we need to define relevant business metrics that align with the goals of the organization. In this case, the primary business goal is to accurately predict high traffic recipes, which can drive more user engagement and potentially increase revenue through advertisements or premium content.\n",
    "\n",
    "### Key Metrics  \n",
    "- **Conversion Rate**: Percentage of predicted high traffic recipes that result in high traffic. This metric helps assess the model's ability to identify recipes that will attract more users.\n",
    "- **User Engagement**: Average time users spend on high traffic recipes. This metric indicates how engaging the predicted high traffic recipes are to users.\n",
    "- **Revenue Impact**: Additional revenue generated from high traffic recipes. This metric quantifies the financial benefit of accurately predicting high traffic recipes.\n",
    "- **False Positive Rate**: Percentage of recipes predicted as high traffic that do not result in high traffic. This metric helps understand the cost of incorrect predictions in terms of wasted resources and potential user dissatisfaction.\n",
    "\n",
    "### Model Performance & Business Metrics\n",
    "To evaluate the performance of the Logistic Regression and Support Vector Machine (SVM) models using the defined business metrics, the following must be analyzed:\n",
    "\n",
    "**Conversion Rate**: The conversion rate, represented by precision, measures the percentage of recipes predicted to be high traffic that actually result in high traffic. A higher conversion rate indicates better model performance in accurately identifying high traffic recipes.\n",
    "- **Logistic Regression**: Precision of 0.846 (84.6%).  \n",
    "- **Random Forest**: Precision of 0.804 (80.4%).  \n",
    "\n",
    "**User Engagement**: Track average time spent on high traffic recipes to compare engagement levels. Higher user engagement can lead to increased user satisfaction, loyalty, and potentially higher ad revenue.  \n",
    "\n",
    "**Revenue Impact**: Analyze additional revenue generated from high traffic recipes predicted by each model. By analyzing the additional revenue generated from high traffic recipes predicted by each model, we can quantify the financial benefit. This is achieved by comparing the revenue before and after implementing the models.  \n",
    "\n",
    "**False Positive Rate**: The false positive rate helps assess the cost of incorrect predictions, indicating how often recipes predicted to be high traffic that do not actually result in high traffic. A lower false positive rate is desirable as it minimizes wasted resources and potential user dissatisfaction.\n",
    "- **Logistic Regression**: 15.4% (100% - 84.6%).  \n",
    "- **Support Vector Machine**: 19.6% (100% - 80.4%).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a42b4-74c4-4326-8062-aee08c0ef366",
   "metadata": {},
   "source": [
    "## Final Summary and Recommendations\n",
    "The model evaluation process for predicting high traffic recipes involved a comprehensive analysis of Logistic Regression and Support Vector Machine (SVM) models. Both models were assessed using various performance metrics, including accuracy, precision, recall, F1 score, and ROC AUC score. The results indicated that both models are effective in predicting high traffic recipes, with each model having its strengths in different metrics.\n",
    "\n",
    "- **Logistic Regression**: This model excelled in precision, making it suitable for applications where minimizing false positives is crucial. It also provided a broader view of feature importance, considering multiple features.\n",
    "- **Support Vector Machine (SVM)**: SVM demonstrated higher recall and F1 scores, indicating its effectiveness in identifying true high traffic recipes. It relied heavily on a few key features, making it efficient but potentially less robust in capturing the full complexity of the data.\n",
    "\n",
    "Cross-validation results further supported the stability and reliability of both models, with consistent mean scores and low standard deviations across multiple metrics. The feature importance analysis highlighted Beverages as the most influential feature, followed by Breakfast, Vegetable, and Potato.\n",
    "\n",
    "**Key Insights from Feature Importances**:\n",
    "- **Beverages**: Most influential for predicting high traffic.\n",
    "- **Breakfast, Vegetables and Potatoes**: Significant contributors to high traffic.\n",
    "- **Pork, Chicken and Chicken Breast**: Medium impact categories.  \n",
    "\n",
    "### Recommendations\n",
    "Based on the evaluation results, the following recommendations are proposed:  \n",
    "\n",
    "**1. Model Selection**  \n",
    "\n",
    "- **Logistic Regression**: Use this model if the primary goal is to minimize false positives and ensure high precision. This is particularly important for applications where incorrect high traffic predictions can lead to wasted resources or user dissatisfaction.  \n",
    "- **Support Vector Machine (SVM)**: Opt for this model if the focus is on capturing all high traffic recipes, as it has higher recall. This is beneficial for scenarios where identifying every potential high traffic recipe is critical.  \n",
    "\n",
    "**2. Feature Optimization**  \n",
    "- Consider using the ensemble method to combine the strengths of both Logistic Regression and SVM models. This approach can provide a balanced and comprehensive understanding of feature importance and improve overall prediction accuracy.\n",
    "- Focus on optimizing content related to the most influential features identified by the ensemble approach (Beverages, Breakfast, Vegetable, and Potato). This can help improve the accuracy of traffic predictions and enhance user engagement. To ensure a balanced mix of content use moderately important categories (Pork and Chicken) to maintain variety and cater to different audience preferences. Only publish in low impact categories occassionally. \n",
    "\n",
    "**Key Insights from Feature Importances**:\n",
    "- **Beverages**: Most influential for predicting high traffic.\n",
    "- **Breakfast, Vegetables and Potatoes**: Significant contributors to high traffic.\n",
    "- **Pork, Chicken and Chicken Breast**: Moderate impact categories.\n",
    "\n",
    "**3. Business Metrics Monitoring**  \n",
    "\n",
    "- Continuously monitor key business metrics such as conversion rate, user engagement, revenue impact, and false positive rate. This will help in assessing the ongoing performance of the models and making necessary adjustments to align with business objectives.  \n",
    "\n",
    "- **Traffic Increase**: Track the percentage increase in traffic after implementing model recommendations.  \n",
    "- **Engagement Rate**: Monitor the average engagement rate (likes, shares, comments) for published recipes.  \n",
    "- **Conversion Rate**: Measure the conversion rate of visitors to subscribers of premium content.  \n",
    "- **Recipe Popularity**: Track the average traffic per recipe category to identify the most popular categories.  \n",
    "\n",
    "**4. Align Marketing with model insights**  \n",
    "\n",
    "- Highlight high-impact categories in marketing campaigns. Promote beverage, breakfast and vegetarian recipes on social media and newsletters to attract more traffic.  \n",
    "- Use feedback and engagement metrics to refine strategy. If certain recipes receive more positive feedback, consider publishing similar recipes.  \n",
    "- Use the insights to plan seasonal recipes. For example, publish more vegetarian recipes during harvest seasons.  \n",
    "- Monitor trends and adjust the recipe publication strategy accordingly. If a particular category gains popularity, increase the frequency of related recipes. \n",
    "\n",
    "**5. Regular Model Updates**  \n",
    "\n",
    "- Regularly update the models with new data to ensure they remain accurate and relevant. This includes re-evaluating feature importance and adjusting hyperparameters as needed.  \n",
    "  \n",
    "By implementing on these recommendations, the business can leverage the predictive power of the models to optimize recipe content for higher traffic, drive more user engagement, and increase revenue. Emphasizing beverages and vegetarian recipes, combined with content optimization and personalized recommendations, will help create a more engaging and user-friendly platform. This data-driven approach will optimize content strategy and achieve business objectives effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f2a05-5866-417a-8631-427401523661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
